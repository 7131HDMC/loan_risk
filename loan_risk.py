# -*- coding: utf-8 -*-
"""loan_risk.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1h3VABqe0-6lPPChAsrVVv0Uls_V1VNYd

# Projeto de Análise de Crédito

Para este projeto, estaremos explorando dados disponíveis publicamente de [LendingClub.com](www.lendingclub.com). Lending Club conecta pessoas que precisam de dinheiro (mutuários) com pessoas que têm dinheiro (investidores). Felizmente, como investidor, você gostaria de investir em pessoas que mostraram um perfil de ter uma alta probabilidade de pagá-lo de volta. Vamos tentar criar um modelo que ajude a prever isso.

O clube de empréstimo teve um [ano muito interessante em 2016](https://en.wikipedia.org/wiki/Lending_Club#2016), então vamos verificar alguns de seus dados e ter em mente o contexto. Esses dados são de antes mesmo de serem públicos.

Utilizaremos os dados de empréstimos de 2007-2010 e tentaremos classificar e prever se o mutuário pagou o empréstimo na íntegra.

Mapeamento das colunas:
* credit.policy: 1 se o cliente atender aos critérios de subscrição de crédito da LendingClub.com e 0 caso contrário.
* purpose: O objetivo do empréstimo (possíveis valores "credit_card", "debt_consolidation", "educacional", "major_purchase", "small_business" e "all_other").
* int.rate: a taxa de juros do empréstimo. Os mutuários julgados por LendingClub.com para serem mais arriscados recebem taxas de juros mais elevadas.
* installment: as parcelas mensais devidas pelo mutuário se o empréstimo for financiado.
* log.annual.inc: O log natural da renda anual auto-relatada do mutuário.
* dti: Ratio dívida / rendimento do tomador do empréstimo (montante da dívida dividido pela receita anual).
* fico: a pontuação de crédito FICO do mutuário.
* days.with.cr.line: O número de dias em que o mutuário teve uma linha de crédito.
* revol.bal: Saldo rotativo do mutuário (montante não pago no final do ciclo de cobrança do cartão de crédito).
* revol.util: taxa de utilização da linha rotativa do mutuário (o valor da linha de crédito usada em relação ao crédito total disponível).
* inq.last.6mths: número de consultas do mutuário por credores nos últimos 6 meses.
* delinq.2yrs: o número de vezes que o mutuário havia passado mais de 30 dias em um pagamento nos últimos 2 anos.
* pub.rec: O número de registros públicos depreciativos do mutuário (arquivamentos de falências, ônus fiscais ou julgamentos).

# Libraries
"""

from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.feature_selection import mutual_info_regression
from sklearn.inspection import permutation_importance
from imblearn.under_sampling import RandomUnderSampler
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from keras.regularizers import l2
from tensorflow import keras


import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd
import numpy as np
import gc

"""## Data review"""

df_loan = pd.read_csv("loan_data.csv")

"""** Use os métodos info(), head(), e describe() em loans. **"""

df_loan.head(5)

df_loan.info()

df_loan.describe()

"""# Análise exploratória de dados

"""



fig, ax = plt.subplots(figsize=(11,9))

df_loan[df_loan["credit.policy"]==1]["fico"].hist(bins=20, alpha=0.63, grid=False, label="Approved Credit Policy")
df_loan[df_loan["credit.policy"]==0]["fico"].hist(bins=20, alpha=0.95, grid=False, label="Denied Credit Policy")

ax.set_xlabel("FICO")
ax.set_ylabel("Amount")
ax.legend()

"""#### Not full paid relationship with FICO"""

fig, ax = plt.subplots(figsize=(10,6))

df_loan[df_loan["not.fully.paid"]==0]["fico"].hist(bins=20, alpha=0.65, grid=False, label="Fully paid")
df_loan[df_loan["not.fully.paid"]==1]["fico"].hist(bins=20, alpha=0.85, grid=False, label="Not fully paid")

ax.set_xlabel("FICO")
ax.set_ylabel("Amount")
ax.legend()

fig, ax = plt.subplots(figsize=(11,9))

sns.countplot(data=df_loan, x="purpose", hue="not.fully.paid")

"""Os dados estão desbalanceados, o que pode nos gerar problemas na modelagem, vamos checar a discrepancias entre as classes"""

print(df_loan["not.fully.paid"].value_counts())
print("\nFraudes representam {:.2f}% do dataset!\n".format((df_loan[df_loan['not.fully.paid'] == 1].shape[0] / df_loan.shape[0]) * 100))

joint_rate_by_fico = sns.jointplot(data=df_loan, y="int.rate", x="fico", palette='Set2', hue="not.fully.paid", height=8)
joint_rate_by_fico.set_axis_labels('Juros', 'FICO')
joint_rate_by_fico.fig.suptitle('Juros e FICO grouped by Inadimplecia', weight='bold', size=14)
plt.show()

"""Check outliers"""

df_loan[
    (df_loan["not.fully.paid"]==1) &
    (df_loan["int.rate"]>0.175) & (df_loan["fico"]>750)]# Outlier case

df_loan[
    (df_loan["not.fully.paid"]==0) &
    (df_loan["int.rate"]<0.075) & (df_loan["fico"]<700)]# Outlier case



lmplot_rate_fico = sns.lmplot(data=df_loan, y="int.rate", x="fico", hue="credit.policy", col="not.fully.paid", palette="Set1")

df_loan.corr()['not.fully.paid'].sort_values(ascending = False).plot(kind='barh')

"""# Configurando os dados

Vamos nos preparar para configurar nossos dados para o nosso modelo de classificação de florestas aleatórias!

Vamos transformar a coluna ***purpose*** em categórica.
"""

df_loan.info()

df_final = pd.get_dummies(df_loan, columns = ["purpose"], drop_first = True)
df_final.head()

"""## Divisão Treino-Teste de dados

"""

features = df_final.columns[(df_final.columns != 'not.fully.paid')]
# features= ["delinq.2yrs", "revol.bal", "inq.last.6mths", "log.annual.inc", "installment", "fico", "credit.policy", "purpose_debt_consolidation", "pub.rec", "days.with.cr.line"]
x = df_final[features]
y = df_final["not.fully.paid"]

x_train, x_valid, y_train, y_valid = train_test_split(x, y, test_size=0.3, random_state=42)

x

"""Function"""

def confusion_matrix_heatmap(conf_mx, cmap="Blues", t_focus=True):
    group_names = ["True Neg","False Pos","False Neg","True Pos"]

    group_percentages = ['{0:.2%}'.format(value) for value in conf_mx.flatten()/np.sum(conf_mx)]

    labels = [f'{v1}\n\n{v3}' for v1, v3 in zip(group_names,group_percentages)]
    labels = np.asarray(labels).reshape(2,2)

    off_diag_mask = [[],[]]  # mask=off_diag_mask
    if t_focus:
        off_diag_mask = np.fliplr(np.eye(*conf_mx.shape, dtype=bool))

    map_sns = sns.heatmap(conf_mx, annot=True, fmt="",  cmap=cmap, cbar=False,  mask=off_diag_mask)
    # map_sns.set_yticklabels(map_sns.get_yticklabels(), va='center')
    # map_sns.patch.set_facecolor('green')
    # map_sns.patch.set_edgecolor('white')
    # map_sns.patch.set_hatch('xx')

    plt.show()

def model_valid_report(model, y, pred, t_focus=True):
    conf_mx = confusion_matrix(y, pred)
    clf_report = classification_report(y, pred)

    print(conf_mx)
    print(clf_report)

    confusion_matrix_heatmap(conf_mx, cmap="Greens",  t_focus=t_focus)

"""Logistic Model

Como os dados estão desbalanceados, podemos observar na matrix de confusão uma descrepancia entre as classes e o recall
"""

log_model = LogisticRegression(solver="newton-cholesky", multi_class="ovr")
log_model.fit(x_train, y_train)
preds_log= log_model.predict(x_valid)
model_valid_report(log_model, y_valid, preds_log, t_focus=False)

random_forest = RandomForestClassifier(random_state=4, n_estimators=8)
random_forest.fit(x_train, y_train)
y_preds = random_forest.predict(x_valid)
model_valid_report(random_forest, y_valid, y_preds, t_focus=False)

gc.collect()

"""Vamos balancear fazer o balanceamento como under and over sampling para verificar os resultados!"""

rus = RandomUnderSampler(sampling_strategy='not minority', random_state=42)
x_train_res, y_train_res = rus.fit_resample(x_train, y_train)

print(pd.Series(y_train_res).value_counts())

"""Vamos treinar o modelo e avaliar a matrix de confusão"""

log_model = LogisticRegression(solver="newton-cholesky", multi_class="ovr")
log_model.fit(x_train_res, y_train_res)
preds_log= log_model.predict(x_valid)
model_valid_report(log_model, y_valid, preds_log, t_focus=False)

"""Vamos implementar uma floresta aleatoria"""

rus = RandomUnderSampler(sampling_strategy='not minority', random_state=11)
x_train_res, y_train_res = rus.fit_resample(x_train, y_train)

random_forest = RandomForestClassifier(random_state=11, n_estimators=105)
random_forest.fit(x_train_res, y_train_res)
y_rf_preds = random_forest.predict(x_valid)
model_valid_report(random_forest, y_valid, y_rf_preds, t_focus=False)

"""Lets create a LSTM model and check its result"""

rus = RandomUnderSampler(sampling_strategy='not minority', random_state=11)
x_train_res, y_train_res = rus.fit_resample(x_train, y_train)

x_train_shape = x_train_res.to_numpy().reshape(x_train_res.shape[0],x_train_res.shape[1],1)
x_valid_shape = x_valid.to_numpy().reshape(x_valid.shape[0],x_valid.shape[1],1)

metrics = ["accuracy",keras.metrics.Recall()]

def get_model(metrics=metrics):
  lstm_model = keras.models.Sequential()
  lstm_model.add(keras.layers.LSTM(18, input_shape=(18,1)))
  lstm_model.add(keras.layers.Dense(18, activation="relu"))
  lstm_model.add(keras.layers.Dense(1, activation="sigmoid"))

  adam = keras.optimizers.Adam(
      learning_rate=3e-5,
  )

  lstm_model.compile(optimizer=adam,
                loss=keras.losses.BinaryCrossentropy(),
                metrics=[metrics])
  return lstm_model

lstm_model = get_model()
lstm_history = lstm_model.fit(
    x_train_shape,y_train_res,
    epochs=19,
    batch_size=19
    , validation_data=(x_valid_shape, y_valid)
)

"""Lets check the LSTM recall


"""

#Plotting LSTM model recall in train and test
fig, ax = plt.subplots(figsize=(8,6))

plt.plot(lstm_history.history["recall_39"],label="train recall")
plt.plot(lstm_history.history["val_recall_39"],label="test recall")
plt.ylabel("Value")
plt.xlabel("Epochs")
plt.title("LSTM Model recall")
plt.legend()
plt.show()





